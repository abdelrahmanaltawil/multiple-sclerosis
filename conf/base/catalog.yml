# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html


# raw data
## project data
2min_walking_test_data:
  type: pandas.ExcelDataSet
  filepath: data/01_raw/2MWT_data.xlsx

## Dr WK paper data
2min_walking_test_paper_data:
  type: pandas.CSVDataSet
  filepath: data/01_raw/2MWT_paper_data.csv
  
  load_args:
    sep: "|"
    decimal: ","


# typed dataset
typed_data:
  type: pandas.ExcelDataSet
  filepath: data/02_intermediate/typed_data.xlsx


# data after integration and cleaning
cleaned_data:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/cleaned_data.pq


# data that will pass to the model
X_train:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/training_input.pq

X_test:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/testing_input.pq


# save machine learning model
untrained_model:
  type: tensorflow.TensorFlowModelDataset
  filepath: data/06_models/untrained_tensorflow_model
  save_args:
    overwrite: True
    save_format: tf

trained_model:
  type: tensorflow.TensorFlowModelDataset
  filepath: data/06_models/trained_tensorflow_model
  load_args:
    compile: False
  save_args:
    overwrite: True
    save_format: tf


# tracking performance
training_metrics_history:
  type: pandas.ExcelDataSet
  filepath: data/08_reporting/metrics_tracking_history.xlsx

training_metrics_history_plot:
  type: plotly.JSONDataSet
  filepath: data/09_tracking/training_metrics_history_plot.json
  versioned: true